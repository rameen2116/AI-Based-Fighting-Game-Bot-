{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "392204ba-ac31-47cb-93df-e96cff05432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for player1_buttons_Up\n",
      "Training model for player1_buttons_Down\n",
      "Training model for player1_buttons_Right\n",
      "Training model for player1_buttons_Left\n",
      "Training model for player1_buttons_Y\n",
      "Training model for player1_buttons_B\n",
      "Training model for player1_buttons_A\n",
      "Training model for player1_buttons_X\n",
      "Training model for player1_buttons_L\n",
      "Training model for player1_buttons_R\n",
      "\n",
      "Overall Evaluation with Offensive Bias (Macro-Average):\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "   player1_buttons_Up       0.06      0.22      0.09       266\n",
      " player1_buttons_Down       0.26      0.34      0.30      1697\n",
      "player1_buttons_Right       0.21      0.39      0.27      1285\n",
      " player1_buttons_Left       0.17      0.24      0.20      1180\n",
      "    player1_buttons_Y       0.07      0.46      0.12       491\n",
      "    player1_buttons_B       0.06      0.47      0.10       266\n",
      "    player1_buttons_A       0.00      0.00      0.00         0\n",
      "    player1_buttons_X       0.00      0.00      0.00         0\n",
      "    player1_buttons_L       0.00      0.00      0.00         0\n",
      "    player1_buttons_R       0.12      0.33      0.17       186\n",
      "\n",
      "            micro avg       0.14      0.34      0.20      5371\n",
      "            macro avg       0.09      0.24      0.12      5371\n",
      "         weighted avg       0.18      0.34      0.23      5371\n",
      "          samples avg       0.11      0.17      0.12      5371\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riyya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\riyya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\riyya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\riyya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\riyya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\riyya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('fight_data.csv')\n",
    "\n",
    "# Feature and label setup\n",
    "input_features = [\n",
    "    'timer', 'has_round_started', 'is_round_over',\n",
    "    'health', 'x_coord', 'y_coord', 'is_jumping', 'is_crouching', 'is_player_in_move', 'move_id',\n",
    "    'Player2 health', 'Player2 x_coord', 'Player2 y_coord',\n",
    "    'Player2 is_jumping', 'Player2 is_crouching', 'Player2 is_player_in_move', 'Player2 move_id'\n",
    "]\n",
    "\n",
    "label_columns = [\n",
    "    'player1_buttons_Up', 'player1_buttons_Down', 'player1_buttons_Right', 'player1_buttons_Left',\n",
    "    'player1_buttons_Y', 'player1_buttons_B', 'player1_buttons_A',\n",
    "    'player1_buttons_X', 'player1_buttons_L', 'player1_buttons_R'\n",
    "]\n",
    "\n",
    "# Offensive buttons\n",
    "offensive_buttons = [\n",
    "    'player1_buttons_Y', 'player1_buttons_B', 'player1_buttons_A',\n",
    "    'player1_buttons_X', 'player1_buttons_L', 'player1_buttons_R'\n",
    "]\n",
    "\n",
    "# Clean labels\n",
    "df[label_columns] = df[label_columns].astype(int)\n",
    "X = df[input_features]\n",
    "y = df[label_columns]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Compute class weights and inflate offensive moves\n",
    "class_weight_dict = {}\n",
    "for col in label_columns:\n",
    "    classes = np.array([0, 1])\n",
    "    if len(np.unique(y_train[col])) < 2:\n",
    "        weights = [1.0, 1.0]\n",
    "    else:\n",
    "        weights = compute_class_weight('balanced', classes=classes, y=y_train[col])\n",
    "        weights = list(weights)\n",
    "\n",
    "    # Boost offensive '1' label\n",
    "    if col in offensive_buttons:\n",
    "        weights[1] *= 2.5\n",
    "\n",
    "    class_weight_dict[col] = {0: weights[0], 1: weights[1]}\n",
    "\n",
    "# Custom scoring function to weight offensive buttons more\n",
    "def offensive_weighted_f1(y_true, y_pred):\n",
    "    scores = []\n",
    "    for i, col in enumerate(label_columns):\n",
    "        weight = 2.0 if col in offensive_buttons else 1.0\n",
    "        f1 = f1_score(y_true[:, i], y_pred[:, i], zero_division=1)\n",
    "        scores.append(f1 * weight)\n",
    "    return np.mean(scores)\n",
    "\n",
    "custom_scorer = make_scorer(offensive_weighted_f1)\n",
    "\n",
    "# Grid Search parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [20],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1]\n",
    "}\n",
    "\n",
    "# Train one tuned model per label\n",
    "best_models = []\n",
    "for col in label_columns:\n",
    "    print(f\"Training model for {col}\")\n",
    "    clf = RandomForestClassifier(random_state=42, class_weight=class_weight_dict[col])\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=3, scoring='f1_macro', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train[col])\n",
    "    best_models.append(grid_search.best_estimator_)\n",
    "\n",
    "# Combine predictions from all models\n",
    "y_pred_combined = np.column_stack([model.predict(X_test) for model in best_models])\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nOverall Evaluation with Offensive Bias (Macro-Average):\")\n",
    "print(classification_report(y_test, y_pred_combined, target_names=label_columns))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d30035c-6de5-42b9-9ace-4eb7f664c6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_fight_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import joblib\n",
    "\n",
    "# Assume X_train and y_train are already prepared\n",
    "base_model = RandomForestClassifier(n_estimators=10, max_depth=20, class_weight=\"balanced\", random_state=42)\n",
    "multi_model = MultiOutputClassifier(base_model)\n",
    "multi_model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(multi_model, 'trained_fight_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a4b578-78fb-4c16-ae1d-1c9fb46f3f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_fight_model_mlp.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import joblib\n",
    "\n",
    "# Define MLP base model\n",
    "mlp_base_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),  # You can tune this\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Wrap in MultiOutputClassifier for multilabel classification\n",
    "mlp_multi_model = MultiOutputClassifier(mlp_base_model)\n",
    "\n",
    "# Train the model\n",
    "mlp_multi_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(mlp_multi_model, 'trained_fight_model_mlp.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6180fe25-b776-4539-ad82-69e3e435e8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
